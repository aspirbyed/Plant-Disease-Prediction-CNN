# -*- coding: utf-8 -*-
"""Plant_Disease.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qwL_AZJfkog84PpcmjiqITPeq4Em8u6u

# üìö Plant Disease Classification with CNN using TensorFlow

---

## üîß 1. Install & Import Dependencies
```python
!pip install tensorflow tensorflow-datasets matplotlib seaborn
```
"""

import tensorflow as tf
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import os
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import (Conv2D, MaxPooling2D, Activation, Dropout,
                                     BatchNormalization, GlobalAveragePooling2D, Dense, Input)
from tensorflow.keras import backend as K
from sklearn.metrics import confusion_matrix, classification_report

"""---

## üì• 2. Load the PlantVillage Dataset
"""

(ds_train, ds_test), ds_info = tfds.load(
    'plant_village',
    split=['train[:80%]', 'train[80%:]'],
    as_supervised=True,
    with_info=True
)

class_names = ds_info.features['label'].names
num_classes = ds_info.features['label'].num_classes
print(f"Number of classes: {num_classes}")
print("Class names:", class_names)

"""---

## üßπ 3. Preprocess & Prepare the Data
"""

IMG_SIZE = 128
BATCH_SIZE = 32

def preprocess(image, label):
    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])
    image = tf.image.random_flip_left_right(image)
    image = tf.image.random_brightness(image, 0.2)
    image = tf.cast(image, tf.float32) / 255.0
    return image, label

# Apply preprocessing
AUTOTUNE = tf.data.AUTOTUNE

ds_train = ds_train.map(preprocess, num_parallel_calls=AUTOTUNE)
ds_test = ds_test.map(preprocess, num_parallel_calls=AUTOTUNE)

ds_train = ds_train.shuffle(1000).batch(BATCH_SIZE).prefetch(AUTOTUNE)
ds_test = ds_test.batch(BATCH_SIZE).prefetch(AUTOTUNE)

"""---

## üñºÔ∏è 4. Visualize Sample Images
"""

plt.figure(figsize=(12, 10))
for images, labels in ds_train.take(1):
    for i in range(15):
        ax = plt.subplot(3, 5, i + 1)
        plt.imshow(images[i].numpy())
        plt.title(class_names[labels[i].numpy()])
        plt.axis("off")
plt.suptitle("Sample Images from Dataset")
plt.show()

"""---

## üìä 5. Visualize Class Distribution
"""

label_counts = {i: 0 for i in range(num_classes)}

# Safely extract integer label
for _, label in tfds.as_numpy(ds_train.unbatch()):
    label = int(label[()])  # Extracts scalar value from 0-dim array
    label_counts[label] += 1

# Plotting
plt.figure(figsize=(15, 6))
sns.barplot(x=[class_names[i] for i in label_counts.keys()], y=list(label_counts.values()))
plt.xticks(rotation=90)
plt.title("Class Distribution in Training Set")
plt.ylabel("Count")
plt.xlabel("Class Name")
plt.show()

"""---

## üèóÔ∏è 6. Build the CNN Model
"""

# Define input shape parameters
height, width, depth = IMG_SIZE, IMG_SIZE, 3
inputShape = (height, width, depth)
chanDim = -1
if K.image_data_format() == "channels_first":
    inputShape = (depth, height, width)
    chanDim = 1

# Create the model
model = Sequential()
model.add(Input(shape=inputShape))

# Conv Block 1
model.add(Conv2D(64, (3, 3), padding="same"))
model.add(Activation("relu"))
model.add(BatchNormalization(axis=chanDim))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

# Conv Block 2
model.add(Conv2D(128, (3, 3), padding="same"))
model.add(Activation("relu"))
model.add(BatchNormalization(axis=chanDim))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

# Conv Block 3
model.add(Conv2D(256, (3, 3), padding="same"))
model.add(Activation("relu"))
model.add(BatchNormalization(axis=chanDim))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

# Global Average Pooling + Dense layers
model.add(GlobalAveragePooling2D())
model.add(Dense(256))
model.add(Activation("relu"))
model.add(BatchNormalization())
model.add(Dropout(0.5))
model.add(Dense(num_classes))
model.add(Activation("softmax"))

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

"""---

## üöÄ 7. Train the Model
"""

from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

# Callbacks
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
lr_reduction = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)

# Train
history = model.fit(
    ds_train,
    validation_data=ds_test,
    epochs=50,
    callbacks=[early_stopping, lr_reduction]
)

"""---

## üìà 8. Visualize Training Performance
"""

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs_range = range(len(acc))

plt.figure(figsize=(16, 6))

plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Train Acc')
plt.plot(epochs_range, val_acc, label='Val Acc')
plt.title('Accuracy over Epochs')
plt.legend()
plt.grid(True)

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Train Loss')
plt.plot(epochs_range, val_loss, label='Val Loss')
plt.title('Loss over Epochs')
plt.legend()
plt.grid(True)

plt.show()

"""---

## üìä 9. Evaluate Model
"""

# Get predictions
true_labels = []
pred_labels = []
for images, labels in ds_test:
    preds = model.predict(images)
    true_labels.extend(labels.numpy())
    pred_labels.extend(np.argmax(preds, axis=1))

# Confusion Matrix
cm = confusion_matrix(true_labels, pred_labels)
plt.figure(figsize=(12, 10))
sns.heatmap(cm, annot=False, cmap='viridis', xticklabels=class_names, yticklabels=class_names)
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.xticks(rotation=90)
plt.yticks(rotation=0)
plt.show()

# Classification Report
print(classification_report(true_labels, pred_labels, target_names=class_names))

"""## üíæ 10. Save the Model"""

model.save('plant_disease_model.keras')

"""## üîÆ 11. Make Predictions on New Images"""

'''
# Load the saved model
_model = tf.keras.models.load_model("plant_disease_model.keras")

def preprocess_single_image(image_path):
    image = tf.io.read_file(image_path)
    image = tf.image.decode_jpeg(image, channels=3)
    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])
    image = tf.cast(image, tf.float32) / 255.0
    return tf.expand_dims(image, axis=0)

# Make prediction
image_path = 'leaf1.jpg'
image = preprocess_single_image(image_path)
pred = _model.predict(image)
label = class_names[np.argmax(pred)]
print(f"[‚òëÔ∏è] Predicted class: {label}")

'''